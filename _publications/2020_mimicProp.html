---
layout: publication
year: 2020
pdf: https://drive.google.com/file/d/1nyfLHXiE5R0qNdW-j1cSQg947jhKn28u/view
title: "MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis"
authors:
  - Muheng Yan
  - Yu-Ru Lin
  - Rebecca Hwa
  - Ali Mert Ertugrul
  - Meiqi Guo
  - Wen-Ting Chung

type:
  - Conference
venue: ICWSM
venue_tags:
venue_url: https://ojs.aaai.org/index.php/ICWSM/issue/archive
tags:
  - Machine Learning
  - Natural Language Processing
  - Social Media
---

Lexicon-based methods and word embeddings are the two widely used approaches for analyzing texts in social media. The choice of an approach can have a significant impact on the reliability of the text analysis. For example, lexicons provide manually curated, domain-specific attributes about alimited set of words, while word embeddings learn to encode some loose semantic interpretations for a much broader set ofwords. Text analysis can benefit from a representation that offers both the broad coverage of word embeddings and the domain knowledge of lexicons. This paper presents MimicProp,a new graph-mode method that learns a lexicon-aligned word embedding. Our approach improves over prior graph-based methods in terms of its interpretability (i.e., lexicon attributescan be recovered) and generalizability (i.e., new words can belearned to incorporate lexicon knowledge). It also effectively improves the performance of downstream analysis applications, such as text classification.