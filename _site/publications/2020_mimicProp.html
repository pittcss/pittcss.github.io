<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="application-name" content="PITT Initiative on the Computational Social Science" />
  <meta name="theme-color" content="#b00" />

  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin />
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700&display=swap"
    rel="stylesheet"
  />
  <link
    href="https://use.fontawesome.com/releases/v5.13.0/css/all.css"
    rel="stylesheet"
  />
  <link href="/styles.css" rel="stylesheet" />

  <link rel="shortcut icon" href="/favicon.ico" />
  <link
    rel="icon"
    type="image/png"
    href="/assets/logo-pittcss-7.png"
    sizes="250x250"
  />

  <link
    rel="alternate"
    type="application/rss+xml"
    title="PITT Initiative on the Computational Social Science"
    href="http://localhost:4000/feed.xml"
  />

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis | PITT Initiative on the Computational Social Science</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis" />
<meta name="author" content="Muheng Yan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lexicon-based methods and word embeddings are the two widely used approaches for analyzing texts in social media. The choice of an approach can have a significant impact on the reliability of the text analysis. For example, lexicons provide manually curated, domain-specific attributes about alimited set of words, while word embeddings learn to encode some loose semantic interpretations for a much broader set ofwords. Text analysis can benefit from a representation that offers both the broad coverage of word embeddings and the domain knowledge of lexicons. This paper presents MimicProp,a new graph-mode method that learns a lexicon-aligned word embedding. Our approach improves over prior graph-based methods in terms of its interpretability (i.e., lexicon attributescan be recovered) and generalizability (i.e., new words can belearned to incorporate lexicon knowledge). It also effectively improves the performance of downstream analysis applications, such as text classification." />
<meta property="og:description" content="Lexicon-based methods and word embeddings are the two widely used approaches for analyzing texts in social media. The choice of an approach can have a significant impact on the reliability of the text analysis. For example, lexicons provide manually curated, domain-specific attributes about alimited set of words, while word embeddings learn to encode some loose semantic interpretations for a much broader set ofwords. Text analysis can benefit from a representation that offers both the broad coverage of word embeddings and the domain knowledge of lexicons. This paper presents MimicProp,a new graph-mode method that learns a lexicon-aligned word embedding. Our approach improves over prior graph-based methods in terms of its interpretability (i.e., lexicon attributescan be recovered) and generalizability (i.e., new words can belearned to incorporate lexicon knowledge). It also effectively improves the performance of downstream analysis applications, such as text classification." />
<link rel="canonical" href="http://localhost:4000/publications/2020_mimicProp.html" />
<meta property="og:url" content="http://localhost:4000/publications/2020_mimicProp.html" />
<meta property="og:site_name" content="PITT Initiative on the Computational Social Science" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-06-11T11:49:04-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Muheng Yan"},"url":"http://localhost:4000/publications/2020_mimicProp.html","description":"Lexicon-based methods and word embeddings are the two widely used approaches for analyzing texts in social media. The choice of an approach can have a significant impact on the reliability of the text analysis. For example, lexicons provide manually curated, domain-specific attributes about alimited set of words, while word embeddings learn to encode some loose semantic interpretations for a much broader set ofwords. Text analysis can benefit from a representation that offers both the broad coverage of word embeddings and the domain knowledge of lexicons. This paper presents MimicProp,a new graph-mode method that learns a lexicon-aligned word embedding. Our approach improves over prior graph-based methods in terms of its interpretability (i.e., lexicon attributescan be recovered) and generalizability (i.e., new words can belearned to incorporate lexicon knowledge). It also effectively improves the performance of downstream analysis applications, such as text classification.","@type":"BlogPosting","headline":"MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis","dateModified":"2023-06-11T11:49:04-04:00","datePublished":"2023-06-11T11:49:04-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/publications/2020_mimicProp.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

  <body>
    <div class="content">
      <header class="bg-white">
        <div class="w-100 mw8 ph4-l ph3 center pt2 pb3 flex items-baseline flex flex-wrap">
          <a href="/" class="dib f2 f3-ns fw6 link black hover-the-red center-s pb3 pr3">
            PittCSS
            <picture>
              <!-- <source
                srcset="/assets/logo-light.svg"
                type="image/svg+xml"
              />
              <source
                srcset="/assets/logo-light.webp"
                type="image/webp"
              /> -->
              <source srcset="/assets/logo-pittcss-7.png" type="image/png"></source>
              <img alt="tentative PittCSS icon" class="pl2 w3" style="margin-bottom: -1rem">
            </picture>
          </a>
          <nav class="mt2 ml-auto-ns lh-copy w-auto-ns w-100 flex flex-column flex-row-ns f4 f5-ns">
            <div class="tc mt0-ns mt2">
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib" href="/about">About</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib" href="/team">People</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib" href="/publications">Publications</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib" href="/news">News</a>
            </div>
            <div class="tc ml3-m ml4-l">
              <!-- <a
                class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib"
                href="https://github.com/pittcss"
                ><i class="fab fa-github mr2"></i>GitHub</a
              > -->
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-the-red link dib" href="https://twitter.com/pittcss">
                <i class="fab fa-twitter mr2"></i>Twitter</a>
            </div>
          </nav>
        </div>
      </header>

      <main>
        <section>
  <div class="pv4 bg-near-white">
    <div class="w-100 mw8 ph4-l ph3 pv4-l pv3 center">
      <h1 class="f2 lh-title measure mt3">
        MimicProp: Learning to Incorporate Lexicon Knowledge into Distributed Word Representation for Social Media Analysis
      </h1>

      

      <div class="flex flex-row flex-wrap items-start mt1">
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset="https://picsolab.github.io/images/people/muheng.jpg"></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Muheng Yan">
          </picture>
          <div class="black mw4 tc">Muheng Yan</div>
        </div>
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset="https://picsolab.github.io/images/people/yurulin_talka.jpg"></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Yu-Ru Lin">
          </picture>
          <div class="black mw4 tc"><a href="http://www.yurulin.com/" class="black hover-the-red link">Yu-Ru Lin</a></div>
        </div>
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset="https://picsolab.github.io/images/people/rebecca.jpg"></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Rebecca Hwa">
          </picture>
          <div class="black mw4 tc"><a href="http://people.cs.pitt.edu/~hwa/" class="black hover-the-red link">Rebecca Hwa</a></div>
        </div>
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset=""></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Ali Mert Ertugrul">
          </picture>
          <div class="black mw4 tc">Ali Mert Ertugrul</div>
        </div>
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset=""></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Meiqi Guo">
          </picture>
          <div class="black mw4 tc">Meiqi Guo</div>
        </div>
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset=""></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Wen-Ting Chung">
          </picture>
          <div class="black mw4 tc">Wen-Ting Chung</div>
        </div>
      
      </div>

      
        <div class="mt3">
          Published at
          
            <a href="https://ojs.aaai.org/index.php/ICWSM/issue/archive">
          
          ICWSM
          
          </a>
          2020
        </div>
      

      
    </div>
  </div>

  <div class="w-100 mw8 ph4-l ph3 center mt4">
    
    <img src="/assets/publications/2020_mimicProp.png" alt="Teaser image" class="mw-100" style="max-height: 600px">

    

    
    
      <h2>Abstract</h2>
      <div class="measure-wide lh-copy">
        Lexicon-based methods and word embeddings are the two widely used approaches for analyzing texts in social media. The choice of an approach can have a significant impact on the reliability of the text analysis. For example, lexicons provide manually curated, domain-specific attributes about alimited set of words, while word embeddings learn to encode some loose semantic interpretations for a much broader set ofwords. Text analysis can benefit from a representation that offers both the broad coverage of word embeddings and the domain knowledge of lexicons. This paper presents MimicProp,a new graph-mode method that learns a lexicon-aligned word embedding. Our approach improves over prior graph-based methods in terms of its interpretability (i.e., lexicon attributescan be recovered) and generalizability (i.e., new words can belearned to incorporate lexicon knowledge). It also effectively improves the performance of downstream analysis applications, such as text classification.
      </div>
    

    
    <h2>Materials</h2>
      <ul class="list pl0">
        
          <li class="mt2"><a href="https://drive.google.com/file/d/1nyfLHXiE5R0qNdW-j1cSQg947jhKn28u/view" class="black link hover-the-red">
            <i class="far fa-file-pdf" aria-hidden="true"></i> PDF
          </a></li>
        
        
        
        
        
        
        
        
        
        
      </ul>
    
  </div>
</section>

      </main>
    </div>

    <footer class="bt dark-gray white mt5 flex-shrink-0">
      <div class="w-100 mw8 ph4-l ph3 center pv5">
        <div class="flex flex-row-ns flex-column">
          <div class="w-50-ns">
            <div class="pv1">
              Hello from Pittsburgh.
              <a href="/team" class="link white dim underline">Come join us!</a>
            </div>
            <!-- <div class="pv1">
              <a
                href="https://github.com/pittcss/pittcss.github.io/edit/master/_publications/2020_mimicProp.html"
                class="link white dim"
                >Edit this page</a
              >
            </div> -->
            <div class="pv1">
              We are
              <a href="https://twitter.com/pittcss" class="link white dim">@pittcss</a>
              on Twitter.
            </div>
            <div class="pt4">
              <abbr title="Last build on 2023-06-11" class="white" style="text-underline-position: under">June 2023</abbr>
            </div>
          </div>
          <div class="w-50-ns">
            <h4 class="white mt0-ns">Links</h4>
            <ul class="list pl0">
              <li>
                <a href="https://xx" class="link white dim pv1 dib">School of Computing and Information</a>
              </li>
              <li>
                <a href="https://xx" class="link white dim pv1 dib">University of Pittsburgh</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
